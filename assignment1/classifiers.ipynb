{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "README\n",
    "\n",
    "This is my sourse code and results of assignment 1 and it is divided into X parts:\n",
    "    a.Data preparation\n",
    "      *This part is mainly about how to import the data from text file and integrate them into a DataFrame object.\n",
    "      *I define a function to handle this work.\n",
    "      *I import all of the data from text files and show it in the 6th block for you check.\n",
    "      *Please check the notes in every blocks for details.\n",
    "    b.Models\n",
    "      *I make 8 models according to the assignment requirement and put each of them in seperate blocks.\n",
    "      *Each blocks of different models is made of the training part and the evaluation part.\n",
    "      *Please check the notes in every blocks for details.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import codecs\n",
    "import glob\n",
    "import pandas as pd  \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import roc_auc_score, precision_score, recall_score\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "    As for this function:\n",
    "    a.Import text files from a folder\n",
    "    b.Give a value to the \"type\" column which \"1\" means positive comment and \"0\" means negtive comment\n",
    "    c.Create a DataFrame object for the next step\n",
    "'''\n",
    "def addData(s):\n",
    "    os.chdir(s)\n",
    "    files = glob.glob('*.txt')        \n",
    "    b=[]\n",
    "    for i in files:\n",
    "        f = open(i,'rb')\n",
    "        a=f.read()\n",
    "        b.append(a)\n",
    "    comdf=pd.DataFrame(b)\n",
    "    path = os.getcwd()\n",
    "    if path[-3:] == 'neg':\n",
    "        comdf['type']=0\n",
    "    elif path[-3:] == 'pos':\n",
    "        comdf['type']=1\n",
    "    comdf.rename(columns={0:'comment'},inplace=True)\n",
    "    return comdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Import all of the text data to a Dataframe object\n",
    "'''\n",
    "df_all=pd.DataFrame(columns=['comment','type'])\n",
    "df_all[['type']] = df_all[['type']].astype(int)\n",
    "n1=addData('E:\\\\document\\\\strange\\\\aclImdb\\\\test\\\\neg')\n",
    "n2=addData('E:\\\\document\\\\strange\\\\aclImdb\\\\test\\\\pos')\n",
    "n3=addData('E:\\\\document\\\\strange\\\\aclImdb\\\\train\\\\neg')\n",
    "n4=addData('E:\\\\document\\\\strange\\\\aclImdb\\\\train\\\\pos')\n",
    "df_all=df_all.append(n1)\n",
    "df_all=df_all.append(n2)\n",
    "df_all=df_all.append(n3)\n",
    "df_all=df_all.append(n4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment</th>\n",
       "      <th>type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>b\"Once again Mr. Costner has dragged out a mov...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>b\"This is an example of why the majority of ac...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>b\"First of all I hate those moronic rappers, w...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>b\"Not even the Beatles could write songs every...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>b\"Brass pictures (movies is not a fitting word...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>b'A funny thing happened to me while watching ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>b\"This German horror film has to be one of the...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>b'Being a long-time fan of Japanese film, I ex...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>b'\"Tokyo Eyes\" tells of a 17 year old Japanese...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>b\"Wealthy horse ranchers in Buenos Aires have ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>b'Cage plays a drunk and gets high critically ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>b\"First of all, I would like to say that I am ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>b\"So tell me - what serious boozer drinks Budw...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>b\"A big disappointment for what was touted as ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>b\"This film is absolutely appalling and awful....</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>b\"Here's a decidedly average Italian post apoc...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>b\"At the bottom end of the apocalypse movie sc...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>b\"Earth has been destroyed in a nuclear holoca...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>b\"Many people are standing in front of the hou...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>b'New York family is the last in their neighbo...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>b'The best thing about \"The Prey\" is the tag l...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>b'This is truly, without exaggerating, one of ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>b'I\\'m a huge fan of both Emily Watson (Breaki...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>b'Sure, most of the slasher films of the 1980\\...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>b'I think that would have been a more appropri...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>b'1980 was certainly a year for bad backwoods ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>b\"Everything everyone has said already pretty ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>b'Uhhh ... so, did they even have writers for ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>b'Oh yeah, this one is definitely a strong con...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>b'Supercraptastic slasher fare, which feels ov...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12470</th>\n",
       "      <td>b'its not as good as the first movie,but its a...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12471</th>\n",
       "      <td>b\"Sure, it was cheesy and nonsensical and at t...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12472</th>\n",
       "      <td>b'SPOILERS THROUGH: &lt;br /&gt;&lt;br /&gt;I really am in...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12473</th>\n",
       "      <td>b\"I have to say, I loved Vanishing Point. I've...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12474</th>\n",
       "      <td>b'To start off with, since this movie is a rem...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12475</th>\n",
       "      <td>b\"I have to agree with most of the other posts...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12476</th>\n",
       "      <td>b'Any movie that shows federal PIGs (Persons I...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12477</th>\n",
       "      <td>b'In Canadian director Kari Skogland\\'s film a...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12478</th>\n",
       "      <td>b\"I saw this movie last night after waiting ag...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12479</th>\n",
       "      <td>b'This movie is about basically human relation...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12480</th>\n",
       "      <td>b'I was surprised at just how much I enjoyed t...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12481</th>\n",
       "      <td>b\"I saw this film in Winnipeg recently - appro...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12482</th>\n",
       "      <td>b\"As perhaps one of the few Canadians who did ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12483</th>\n",
       "      <td>b\"I was very moved by the story and because I ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12484</th>\n",
       "      <td>b\"What I loved about the on-screen adaptation ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12485</th>\n",
       "      <td>b\"I had a chance to see a screening of this mo...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12486</th>\n",
       "      <td>b\"This is a really interesting movie. It is an...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12487</th>\n",
       "      <td>b'I saw the movie recently and really liked it...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12488</th>\n",
       "      <td>b\"I thought this movie was hysterical. I have ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12489</th>\n",
       "      <td>b'...this is a classic with so many great dial...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12490</th>\n",
       "      <td>b'The most hillarious and funny Brooks movie I...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12491</th>\n",
       "      <td>b'\"Life stinks\" is a parody of life and death,...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12492</th>\n",
       "      <td>b\"This is the kind of film you want to see wit...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12493</th>\n",
       "      <td>b\"I have not read the other comments on the fi...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12494</th>\n",
       "      <td>b'Life Stinks (1991) was a step below Mel Broo...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12495</th>\n",
       "      <td>b'Seeing as the vote average was pretty low, a...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12496</th>\n",
       "      <td>b'The plot had some wretched, unbelievable twi...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12497</th>\n",
       "      <td>b\"I am amazed at how this movie(and most other...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12498</th>\n",
       "      <td>b\"A Christmas Together actually came before my...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12499</th>\n",
       "      <td>b'Working-class romantic drama from director M...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>50000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 comment  type\n",
       "0      b\"Once again Mr. Costner has dragged out a mov...     0\n",
       "1      b\"This is an example of why the majority of ac...     0\n",
       "2      b\"First of all I hate those moronic rappers, w...     0\n",
       "3      b\"Not even the Beatles could write songs every...     0\n",
       "4      b\"Brass pictures (movies is not a fitting word...     0\n",
       "5      b'A funny thing happened to me while watching ...     0\n",
       "6      b\"This German horror film has to be one of the...     0\n",
       "7      b'Being a long-time fan of Japanese film, I ex...     0\n",
       "8      b'\"Tokyo Eyes\" tells of a 17 year old Japanese...     0\n",
       "9      b\"Wealthy horse ranchers in Buenos Aires have ...     0\n",
       "10     b'Cage plays a drunk and gets high critically ...     0\n",
       "11     b\"First of all, I would like to say that I am ...     0\n",
       "12     b\"So tell me - what serious boozer drinks Budw...     0\n",
       "13     b\"A big disappointment for what was touted as ...     0\n",
       "14     b\"This film is absolutely appalling and awful....     0\n",
       "15     b\"Here's a decidedly average Italian post apoc...     0\n",
       "16     b\"At the bottom end of the apocalypse movie sc...     0\n",
       "17     b\"Earth has been destroyed in a nuclear holoca...     0\n",
       "18     b\"Many people are standing in front of the hou...     0\n",
       "19     b'New York family is the last in their neighbo...     0\n",
       "20     b'The best thing about \"The Prey\" is the tag l...     0\n",
       "21     b'This is truly, without exaggerating, one of ...     0\n",
       "22     b'I\\'m a huge fan of both Emily Watson (Breaki...     0\n",
       "23     b'Sure, most of the slasher films of the 1980\\...     0\n",
       "24     b'I think that would have been a more appropri...     0\n",
       "25     b'1980 was certainly a year for bad backwoods ...     0\n",
       "26     b\"Everything everyone has said already pretty ...     0\n",
       "27     b'Uhhh ... so, did they even have writers for ...     0\n",
       "28     b'Oh yeah, this one is definitely a strong con...     0\n",
       "29     b'Supercraptastic slasher fare, which feels ov...     0\n",
       "...                                                  ...   ...\n",
       "12470  b'its not as good as the first movie,but its a...     1\n",
       "12471  b\"Sure, it was cheesy and nonsensical and at t...     1\n",
       "12472  b'SPOILERS THROUGH: <br /><br />I really am in...     1\n",
       "12473  b\"I have to say, I loved Vanishing Point. I've...     1\n",
       "12474  b'To start off with, since this movie is a rem...     1\n",
       "12475  b\"I have to agree with most of the other posts...     1\n",
       "12476  b'Any movie that shows federal PIGs (Persons I...     1\n",
       "12477  b'In Canadian director Kari Skogland\\'s film a...     1\n",
       "12478  b\"I saw this movie last night after waiting ag...     1\n",
       "12479  b'This movie is about basically human relation...     1\n",
       "12480  b'I was surprised at just how much I enjoyed t...     1\n",
       "12481  b\"I saw this film in Winnipeg recently - appro...     1\n",
       "12482  b\"As perhaps one of the few Canadians who did ...     1\n",
       "12483  b\"I was very moved by the story and because I ...     1\n",
       "12484  b\"What I loved about the on-screen adaptation ...     1\n",
       "12485  b\"I had a chance to see a screening of this mo...     1\n",
       "12486  b\"This is a really interesting movie. It is an...     1\n",
       "12487  b'I saw the movie recently and really liked it...     1\n",
       "12488  b\"I thought this movie was hysterical. I have ...     1\n",
       "12489  b'...this is a classic with so many great dial...     1\n",
       "12490  b'The most hillarious and funny Brooks movie I...     1\n",
       "12491  b'\"Life stinks\" is a parody of life and death,...     1\n",
       "12492  b\"This is the kind of film you want to see wit...     1\n",
       "12493  b\"I have not read the other comments on the fi...     1\n",
       "12494  b'Life Stinks (1991) was a step below Mel Broo...     1\n",
       "12495  b'Seeing as the vote average was pretty low, a...     1\n",
       "12496  b'The plot had some wretched, unbelievable twi...     1\n",
       "12497  b\"I am amazed at how this movie(and most other...     1\n",
       "12498  b\"A Christmas Together actually came before my...     1\n",
       "12499  b'Working-class romantic drama from director M...     1\n",
       "\n",
       "[50000 rows x 2 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "Show the DataFrame\n",
    "'''\n",
    "df_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "splitting in train and test stes \n",
    "'''\n",
    "X = df_all[\"comment\"]\n",
    "y = df_all[\"type\"]\n",
    "X_train,X_test,y_train, y_test = train_test_split(\n",
    "        X,y,test_size=0.3, stratify=y, random_state=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC      : 0.8447\n",
      "Precision: 0.8702\n",
      "Recall   : 0.8101\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "CounterVectorizer + Naive Bayes\n",
    "'''\n",
    "\n",
    "'''Model training'''\n",
    "clf = Pipeline([\n",
    "        ('vec',CountVectorizer()),\n",
    "        ('nb',MultinomialNB())\n",
    "        ])\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "'''Evaluation'''\n",
    "y_pred = clf.predict(X_test)\n",
    "print(\"AUC      : {:.4f}\".format(roc_auc_score(y_test,y_pred)))\n",
    "print(\"Precision: {:.4f}\".format(precision_score(y_test,y_pred)))\n",
    "print(\"Recall   : {:.4f}\".format(recall_score(y_test,y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('CVNB.pickle', 'wb') as fw:\n",
    "    pickle.dump(clf, fw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC      : 0.8579\n",
      "Precision: 0.8804\n",
      "Recall   : 0.8284\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "TfidfVectorizer + Naive Bayes\n",
    "'''\n",
    "\n",
    "'''Model training'''\n",
    "clf = Pipeline([\n",
    "        ('vec',TfidfVectorizer()),\n",
    "        ('nb',MultinomialNB())\n",
    "        ])\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "'''Evaluation'''\n",
    "y_pred = clf.predict(X_test)\n",
    "print(\"AUC      : {:.4f}\".format(roc_auc_score(y_test,y_pred)))\n",
    "print(\"Precision: {:.4f}\".format(precision_score(y_test,y_pred)))\n",
    "print(\"Recall   : {:.4f}\".format(recall_score(y_test,y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('TVNB.pickle', 'wb') as fw:\n",
    "    pickle.dump(clf, fw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC      : 0.8873\n",
      "Precision: 0.8848\n",
      "Recall   : 0.8907\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "CounterVectorizer + Logistic Regression\n",
    "'''\n",
    "\n",
    "'''Model training'''\n",
    "clf = Pipeline([\n",
    "        ('vec',CountVectorizer()),\n",
    "        ('lr',LogisticRegression())\n",
    "        ])\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "'''Evaluation'''\n",
    "y_pred = clf.predict(X_test)\n",
    "print(\"AUC      : {:.4f}\".format(roc_auc_score(y_test,y_pred)))\n",
    "print(\"Precision: {:.4f}\".format(precision_score(y_test,y_pred)))\n",
    "print(\"Recall   : {:.4f}\".format(recall_score(y_test,y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('CVLR.pickle', 'wb') as fw:\n",
    "    pickle.dump(clf, fw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC      : 0.8953\n",
      "Precision: 0.8880\n",
      "Recall   : 0.9047\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "TfidfVectorizer + Logistic Regression\n",
    "'''\n",
    "\n",
    "'''Model training'''\n",
    "clf = Pipeline([\n",
    "        ('vec',TfidfVectorizer()),\n",
    "        ('lr',LogisticRegression())\n",
    "        ])\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "'''Evaluation'''\n",
    "y_pred = clf.predict(X_test)\n",
    "print(\"AUC      : {:.4f}\".format(roc_auc_score(y_test,y_pred)))\n",
    "print(\"Precision: {:.4f}\".format(precision_score(y_test,y_pred)))\n",
    "print(\"Recall   : {:.4f}\".format(recall_score(y_test,y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('TVLR.pickle', 'wb') as fw:\n",
    "    pickle.dump(clf, fw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC      : 0.8799\n",
      "Precision: 0.8949\n",
      "Recall   : 0.8609\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "CounterVectorizer + Naive Bayes + bigram\n",
    "'''\n",
    "\n",
    "'''Model training'''\n",
    "clf = Pipeline([\n",
    "        ('vec',CountVectorizer(ngram_range=(1,2))),\n",
    "        ('nb',MultinomialNB())\n",
    "        ])\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "'''Evaluation'''\n",
    "y_pred = clf.predict(X_test)\n",
    "print(\"AUC      : {:.4f}\".format(roc_auc_score(y_test,y_pred)))\n",
    "print(\"Precision: {:.4f}\".format(precision_score(y_test,y_pred)))\n",
    "print(\"Recall   : {:.4f}\".format(recall_score(y_test,y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('CVNBbigram.pickle', 'wb') as fw:\n",
    "    pickle.dump(clf, fw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC      : 0.8889\n",
      "Precision: 0.9098\n",
      "Recall   : 0.8635\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "TfidfVectorizer + Naive Bayes + bigram\n",
    "'''\n",
    "\n",
    "'''Model training'''\n",
    "clf = Pipeline([\n",
    "        ('vec',TfidfVectorizer(ngram_range=(1,2))),\n",
    "        ('nb',MultinomialNB())\n",
    "        ])\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "'''Evaluation'''\n",
    "y_pred = clf.predict(X_test)\n",
    "print(\"AUC      : {:.4f}\".format(roc_auc_score(y_test,y_pred)))\n",
    "print(\"Precision: {:.4f}\".format(precision_score(y_test,y_pred)))\n",
    "print(\"Recall   : {:.4f}\".format(recall_score(y_test,y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('TVNBbigram.pickle', 'wb') as fw:\n",
    "    pickle.dump(clf, fw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC      : 0.9071\n",
      "Precision: 0.8997\n",
      "Recall   : 0.9163\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "CounterVectorizer + Logistic Regression + bigram\n",
    "'''\n",
    "\n",
    "'''Model training'''\n",
    "clf = Pipeline([\n",
    "        ('vec',CountVectorizer(ngram_range=(1,2))),\n",
    "        ('lr',LogisticRegression())\n",
    "        ])\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "'''Evaluation'''\n",
    "y_pred = clf.predict(X_test)\n",
    "print(\"AUC      : {:.4f}\".format(roc_auc_score(y_test,y_pred)))\n",
    "print(\"Precision: {:.4f}\".format(precision_score(y_test,y_pred)))\n",
    "print(\"Recall   : {:.4f}\".format(recall_score(y_test,y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('CVLRbigram.pickle', 'wb') as fw:\n",
    "    pickle.dump(clf, fw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC      : 0.8960\n",
      "Precision: 0.8886\n",
      "Recall   : 0.9055\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "TfidfVectorizer + Logistic Regression + bigram\n",
    "'''\n",
    "\n",
    "'''Model training'''\n",
    "clf = Pipeline([\n",
    "        ('vec',TfidfVectorizer(ngram_range=(1,2))),\n",
    "        ('lr',LogisticRegression())\n",
    "        ])\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "'''Evaluation'''\n",
    "y_pred = clf.predict(X_test)\n",
    "print(\"AUC      : {:.4f}\".format(roc_auc_score(y_test,y_pred)))\n",
    "print(\"Precision: {:.4f}\".format(precision_score(y_test,y_pred)))\n",
    "print(\"Recall   : {:.4f}\".format(recall_score(y_test,y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('TVLRbigram.pickle', 'wb') as fw:\n",
    "    pickle.dump(clf, fw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "This is the form of 9 different models' performance below:\n",
    " _________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________\n",
    "|          |CounterVectorizer + Naive Bayes  |  TfidfVectorizer + Naive Bayes  |  CounterVectorizer + Logistic Regression  |  TfidfVectorizer + Logistic Regression  |  CounterVectorizer + Naive Bayes + bigram  |  TfidfVectorizer + Naive Bayes + bigram  |  CounterVectorizer + Logistic Regression + bigram  |  TfidfVectorizer + Logistic Regression + bigram  |  fastText  |\n",
    " ---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
    "| AUC      |0.8447                           |0.8579                           |0.8873                                     |0.8953                                   |0.8799                                      |0.8889                                    |0.9071                                              |0.8960                                            |None        |\n",
    " --------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- \n",
    "| Precision|0.8702                           |0.8804                           |0.8848                                     |0.8880                                   |0.8949                                      |0.9098                                    |0.8997                                              |0.8886                                            |0.8952      |\n",
    " ---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
    "| Recall   |0.8101                           |0.8284                           |0.8907                                     |0.9047                                   |0.8609                                      |0.8635                                    |0.9163                                              |0.9055                                            |0.8952      |\n",
    " ---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
    "\"CounterVectorizer + Logistic Regression + bigram\" model perform best on AUC\n",
    "\"TfidfVectorizer + Naive Bayes + bigram\" model perform best on Precision\n",
    "\"CounterVectorizer + Logistic Regression + bigram\" model perform best on Recall\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
